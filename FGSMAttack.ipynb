{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cleverhans\n",
      "  Using cached cleverhans-4.0.0-py3-none-any.whl (92 kB)\n",
      "Collecting easydict\n",
      "  Using cached easydict-1.9-py3-none-any.whl\n",
      "Collecting tensorflow-probability\n",
      "  Using cached tensorflow_probability-0.15.0-py2.py3-none-any.whl (5.7 MB)\n",
      "Collecting absl-py\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: matplotlib in /Users/liuchu/anaconda3/lib/python3.6/site-packages (from cleverhans) (2.2.2)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Requirement already satisfied: numpy in /Users/liuchu/anaconda3/lib/python3.6/site-packages (from cleverhans) (1.14.3)\n",
      "Requirement already satisfied: pycodestyle in /Users/liuchu/anaconda3/lib/python3.6/site-packages (from cleverhans) (2.4.0)\n",
      "Collecting mnist\n",
      "  Using cached mnist-0.2.2-py2.py3-none-any.whl (3.5 kB)\n",
      "Requirement already satisfied: nose in /Users/liuchu/anaconda3/lib/python3.6/site-packages (from cleverhans) (1.3.7)\n",
      "Requirement already satisfied: scipy in /Users/liuchu/anaconda3/lib/python3.6/site-packages (from cleverhans) (1.1.0)\n",
      "Requirement already satisfied: six in /Users/liuchu/anaconda3/lib/python3.6/site-packages (from cleverhans) (1.12.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/liuchu/anaconda3/lib/python3.6/site-packages (from matplotlib->cleverhans) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/liuchu/anaconda3/lib/python3.6/site-packages (from matplotlib->cleverhans) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/liuchu/anaconda3/lib/python3.6/site-packages (from matplotlib->cleverhans) (2.8.0)\n",
      "Requirement already satisfied: pytz in /Users/liuchu/anaconda3/lib/python3.6/site-packages (from matplotlib->cleverhans) (2018.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/liuchu/anaconda3/lib/python3.6/site-packages (from matplotlib->cleverhans) (1.0.1)\n",
      "Collecting dm-tree\n",
      "  Using cached dm-tree-0.1.6.tar.gz (33 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: gast>=0.3.2 in /Users/liuchu/anaconda3/lib/python3.6/site-packages (from tensorflow-probability->cleverhans) (0.5.3)\n",
      "Collecting cloudpickle>=1.3\n",
      "  Using cached cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: decorator in /Users/liuchu/anaconda3/lib/python3.6/site-packages (from tensorflow-probability->cleverhans) (4.3.0)\n",
      "Requirement already satisfied: setuptools in /Users/liuchu/anaconda3/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->cleverhans) (39.1.0)\n",
      "Building wheels for collected packages: dm-tree\n",
      "  Building wheel for dm-tree (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /Users/liuchu/anaconda3/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/mt/vx47wy9133q_bd08cwl0q0g00000gn/T/pip-install-j53q48qk/dm-tree_037a4e4dc8284265891c24bfc9525ba7/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/mt/vx47wy9133q_bd08cwl0q0g00000gn/T/pip-install-j53q48qk/dm-tree_037a4e4dc8284265891c24bfc9525ba7/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /private/var/folders/mt/vx47wy9133q_bd08cwl0q0g00000gn/T/pip-wheel-2l_l1i9d\n",
      "       cwd: /private/var/folders/mt/vx47wy9133q_bd08cwl0q0g00000gn/T/pip-install-j53q48qk/dm-tree_037a4e4dc8284265891c24bfc9525ba7/\n",
      "  Complete output (15 lines):\n",
      "  /Users/liuchu/anaconda3/lib/python3.6/distutils/dist.py:261: UserWarning: Unknown distribution option: 'long_description_content_type'\n",
      "    warnings.warn(msg)\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.macosx-10.7-x86_64-3.6\n",
      "  creating build/lib.macosx-10.7-x86_64-3.6/tree\n",
      "  copying tree/__init__.py -> build/lib.macosx-10.7-x86_64-3.6/tree\n",
      "  copying tree/tree_test.py -> build/lib.macosx-10.7-x86_64-3.6/tree\n",
      "  copying tree/tree_benchmark.py -> build/lib.macosx-10.7-x86_64-3.6/tree\n",
      "  running build_ext\n",
      "  bazel build //tree:_tree --symlink_prefix=build/temp.macosx-10.7-x86_64-3.6/bazel- --compilation_mode=opt\n",
      "  unable to execute 'bazel': No such file or directory\n",
      "  error: command 'bazel' failed with exit status 1\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for dm-tree\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for dm-tree\n",
      "Failed to build dm-tree\n",
      "Installing collected packages: dm-tree, cloudpickle, absl-py, tensorflow-probability, mnist, joblib, easydict, cleverhans\n",
      "    Running setup.py install for dm-tree ... \u001b[?25lerror\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Users/liuchu/anaconda3/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/mt/vx47wy9133q_bd08cwl0q0g00000gn/T/pip-install-j53q48qk/dm-tree_037a4e4dc8284265891c24bfc9525ba7/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/mt/vx47wy9133q_bd08cwl0q0g00000gn/T/pip-install-j53q48qk/dm-tree_037a4e4dc8284265891c24bfc9525ba7/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/mt/vx47wy9133q_bd08cwl0q0g00000gn/T/pip-record-7oke0vch/install-record.txt --single-version-externally-managed --compile --install-headers /Users/liuchu/anaconda3/include/python3.6m/dm-tree\n",
      "         cwd: /private/var/folders/mt/vx47wy9133q_bd08cwl0q0g00000gn/T/pip-install-j53q48qk/dm-tree_037a4e4dc8284265891c24bfc9525ba7/\n",
      "    Complete output (15 lines):\n",
      "    /Users/liuchu/anaconda3/lib/python3.6/distutils/dist.py:261: UserWarning: Unknown distribution option: 'long_description_content_type'\n",
      "      warnings.warn(msg)\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.macosx-10.7-x86_64-3.6\n",
      "    creating build/lib.macosx-10.7-x86_64-3.6/tree\n",
      "    copying tree/__init__.py -> build/lib.macosx-10.7-x86_64-3.6/tree\n",
      "    copying tree/tree_test.py -> build/lib.macosx-10.7-x86_64-3.6/tree\n",
      "    copying tree/tree_benchmark.py -> build/lib.macosx-10.7-x86_64-3.6/tree\n",
      "    running build_ext\n",
      "    bazel build //tree:_tree --symlink_prefix=build/temp.macosx-10.7-x86_64-3.6/bazel- --compilation_mode=opt\n",
      "    unable to execute 'bazel': No such file or directory\n",
      "    error: command 'bazel' failed with exit status 1\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: /Users/liuchu/anaconda3/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/mt/vx47wy9133q_bd08cwl0q0g00000gn/T/pip-install-j53q48qk/dm-tree_037a4e4dc8284265891c24bfc9525ba7/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/mt/vx47wy9133q_bd08cwl0q0g00000gn/T/pip-install-j53q48qk/dm-tree_037a4e4dc8284265891c24bfc9525ba7/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/mt/vx47wy9133q_bd08cwl0q0g00000gn/T/pip-record-7oke0vch/install-record.txt --single-version-externally-managed --compile --install-headers /Users/liuchu/anaconda3/include/python3.6m/dm-tree Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#Install the dependencies\n",
    "\n",
    "!pip install cleverhans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cleverhans'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5d15a8ef7953>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcleverhans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcleverhans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcleverhans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMNIST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cleverhans'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from cleverhans.compat import flags\n",
    "from cleverhans.train import train\n",
    "from cleverhans.dataset import MNIST\n",
    "from cleverhans.utils import AccuracyReport\n",
    "from cleverhans.utils_tf import model_eval\n",
    "\n",
    "#Attack on PyTorch\n",
    "from cleverhans.future.torch.attacks.fast_gradient_method import fast_gradient_method\n",
    "\n",
    "#advertorch attacks\n",
    "from advertorch.attacks import CarliniWagnerL2Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a simple network\n",
    "class LeNet5(torch.nn.Module):          \n",
    "     \n",
    "    def __init__(self):     \n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5, padding=2)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)   \n",
    "        self.fc2 = nn.Linear(120, 84)       \n",
    "        self.fc3 = nn.Linear(84, 10)    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  \n",
    "        x = F.max_pool2d(x, 2) \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return F.log_softmax(x,dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = flags.FLAGS\n",
    "NB_EPOCHS = 2\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = .001\n",
    "\n",
    "#Training the Network\n",
    "def trainTorch(torch_model, train_loader, test_loader,\n",
    "        nb_epochs=NB_EPOCHS, batch_size=BATCH_SIZE, train_end=-1, test_end=-1, learning_rate=LEARNING_RATE, optimizer=None):\n",
    "\n",
    "    train_loss = []\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    step = 0\n",
    "    for _epoch in range(nb_epochs):\n",
    "      for xs, ys in train_loader:\n",
    "        xs, ys = Variable(xs), Variable(ys)\n",
    "        if torch.cuda.is_available():\n",
    "          xs, ys = xs.cuda(), ys.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        preds = torch_model(xs)\n",
    "        # print(\"HI\")\n",
    "        loss = F.nll_loss(preds, ys)\n",
    "        # print(\"HADSFSDF\")\n",
    "        loss.backward()  # calc gradients\n",
    "        train_loss.append(loss.data.item())\n",
    "        optimizer.step()  # update gradients\n",
    "\n",
    "        preds_np = preds.cpu().detach().numpy()\n",
    "        correct += (np.argmax(preds_np, axis=1) == ys.cpu().detach().numpy()).sum()\n",
    "        total += train_loader.batch_size\n",
    "        step += 1\n",
    "        if total % 1000 == 0:\n",
    "          acc = float(correct) / total\n",
    "          print('[%s] Training accuracy: %.2f%%' % (step, acc * 100))\n",
    "          total = 0\n",
    "          correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate results on clean data\n",
    "def evalClean(model1=None, test_loader=None):\n",
    "    print(\"Evaluating single model results on clean data\")\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "      model1.eval()\n",
    "      for xs, ys in test_loader:\n",
    "        xs, ys = Variable(xs), Variable(ys)\n",
    "        if torch.cuda.is_available():\n",
    "          xs, ys = xs.cuda(), ys.cuda()\n",
    "        preds1 = model1(xs)\n",
    "        preds_np1 = preds1.cpu().detach().numpy()\n",
    "        finalPred = np.argmax(preds_np1, axis=1)\n",
    "        correct += (finalPred == ys.cpu().detach().numpy()).sum()\n",
    "        total += len(xs)\n",
    "    acc = float(correct) / total\n",
    "    print('Clean accuracy: %.2f%%' % (acc * 100))\n",
    "\n",
    "#Evaluate results on adversarially perturbed \n",
    "def evalAdvAttack(fgsm_model=None, test_loader=None):\n",
    "    print(\"Evaluating single model results on adv data\")\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    fgsm_model.eval()\n",
    "    for xs, ys in test_loader:\n",
    "      if torch.cuda.is_available():\n",
    "        xs, ys = xs.cuda(), ys.cuda()\n",
    "      #pytorch fast gradient method\n",
    "      xs = fast_gradient_method(fgsm_model, xs, eps=0.3, norm=np.inf, clip_min=0., clip_max=1.)\n",
    "      # xs = fast_gradient_method(fgsm_model, xs, eps=0.1, norm=np.inf)\n",
    "      xs, ys = Variable(xs), Variable(ys)\n",
    "      preds1 = fgsm_model(xs)\n",
    "      preds_np1 = preds1.cpu().detach().numpy()\n",
    "      finalPred = np.argmax(preds_np1, axis=1)\n",
    "      correct += (finalPred == ys.cpu().detach().numpy()).sum()\n",
    "      total += test_loader.batch_size\n",
    "    acc = float(correct) / total\n",
    "    print('Adv accuracy: {:.3f}ï¼…'.format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial Training\n",
    "def advTrain(torch_model, train_loader, test_loader,\n",
    "        nb_epochs=NB_EPOCHS, batch_size=BATCH_SIZE, train_end=-1, test_end=-1, learning_rate=LEARNING_RATE):\n",
    "    optimizer = optim.Adam(torch_model.parameters(), lr=learning_rate)\n",
    "    train_loss = []\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    totalAdv = 0\n",
    "    correctAdv = 0\n",
    "    step = 0\n",
    "    # breakstep = 0\n",
    "    for _epoch in range(nb_epochs):\n",
    "      for xs, ys in train_loader:\n",
    "        #Normal Training\n",
    "        xs, ys = Variable(xs), Variable(ys)\n",
    "        if torch.cuda.is_available():\n",
    "          xs, ys = xs.cuda(), ys.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        preds = torch_model(xs)\n",
    "        loss = F.nll_loss(preds, ys)\n",
    "        loss.backward()  # calc gradients\n",
    "        train_loss.append(loss.data.item())\n",
    "        optimizer.step()  # update gradients\n",
    "        preds_np = preds.cpu().detach().numpy()\n",
    "        correct += (np.argmax(preds_np, axis=1) == ys.cpu().detach().numpy()).sum()\n",
    "        total += train_loader.batch_size\n",
    "\n",
    "        #Adversarial Training\n",
    "        xs = fast_gradient_method(torch_model, xs, eps=0.3, norm=np.inf, clip_min=0., clip_max=1.)\n",
    "        xs, ys = Variable(xs), Variable(ys)\n",
    "        if torch.cuda.is_available():\n",
    "            xs, ys = xs.cuda(), ys.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        preds = torch_model(xs)\n",
    "        loss = F.nll_loss(preds, ys)\n",
    "        loss.backward()  # calc gradients\n",
    "        train_loss.append(loss.data.item())\n",
    "        optimizer.step()  # update gradients\n",
    "        preds_np = preds.cpu().detach().numpy()\n",
    "        correctAdv += (np.argmax(preds_np, axis=1) == ys.cpu().detach().numpy()).sum()\n",
    "        totalAdv += train_loader.batch_size\n",
    "        \n",
    "        step += 1\n",
    "        if total % 1000 == 0:\n",
    "          acc = float(correct) / total\n",
    "          print('[%s] Clean Training accuracy: %.2f%%' % (step, acc * 100))\n",
    "          total = 0\n",
    "          correct = 0\n",
    "          accAdv = float(correctAdv) / totalAdv\n",
    "          print('[%s] Adv Training accuracy: %.2f%%' % (step, accAdv * 100))\n",
    "          totalAdv = 0\n",
    "          correctAdv = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize model and data loader\n",
    "model1 = LeNet5()\n",
    "if torch.cuda.is_available():\n",
    "  model1 = model1.cuda()\n",
    "nb_epochs = 4\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "train_end = -1\n",
    "test_end = -1\n",
    "report = AccuracyReport()\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True,\n",
    "                    transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model\n",
    "print(\"Training Model\")\n",
    "optimizer = optim.Adam(model1.parameters(), lr=learning_rate)\n",
    "trainTorch(model1, train_loader, test_loader, nb_epochs, batch_size, train_end, test_end, learning_rate, optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "evalClean(model1, test_loader)\n",
    "evalAdvAttack(model1, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training on Adversarial Samples\")\n",
    "advTrain(model1, train_loader, test_loader, nb_epochs, batch_size, train_end, test_end, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating Again\n",
    "evalClean(model1, test_loader)\n",
    "evalAdvAttack(model1, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
